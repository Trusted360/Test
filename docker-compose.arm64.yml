# ARM64-specific overrides for Trusted360
# Use with: docker-compose -f docker-compose.yml -f docker-compose.arm64.yml up

version: '3.8'

services:
  # Ollama optimizations for ARM64
  ollama:
    environment:
      - OLLAMA_ORIGINS=*
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=2m  # Reduced keep-alive for ARM
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_MAX_LOADED_MODELS=1  # Limit loaded models on ARM
    deploy:
      resources:
        limits:
          memory: 2G  # Reduced memory limit for ARM
        reservations:
          memory: 1G

  # API optimizations for ARM64
  api:
    environment:
      NODE_ENV: development
      DATABASE_URL: postgres://trusted360:trusted360_password@postgres:5432/trusted360
      REDIS_URL: redis://redis:6379
      SKIP_MIGRATIONS: "false"
      OLLAMA_URL: http://ollama:11434
      OLLAMA_MODEL_PRIMARY: llama3.2:1b-instruct-q4_K_M  # Smaller model for ARM
      OLLAMA_MODEL_FALLBACK: llama3.2:1b-instruct-q4_K_M
      CHAT_CONTEXT_WINDOW: 4096  # Reduced context window
      CHAT_MAX_HISTORY: 5  # Reduced history
      CHAT_RESPONSE_TIMEOUT: 60000  # Increased timeout for slower ARM
    deploy:
      resources:
        limits:
          memory: 512M  # Reduced memory for ARM
        reservations:
          memory: 128M

  # PostgreSQL optimizations for ARM64
  postgres:
    command: >
      postgres
      -c shared_buffers=64MB
      -c effective_cache_size=256MB
      -c maintenance_work_mem=32MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M

  # Redis optimizations for ARM64
  redis:
    command: redis-server --appendonly yes --maxmemory 128mb --maxmemory-policy allkeys-lru
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M